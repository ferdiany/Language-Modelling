# -*- coding: utf-8 -*-
"""1301174684_Tugas2_LM_Fixed.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kjV9Pcm1S4og3pQrsq5DM6WbRVpfSSZR
"""

#Import Library yang dibutuhkan
import nltk
import pandas as pd
import math
nltk.download('punkt')

#Membuat list untuk menampung data 20 artikel
judul = ["Aplikasi Online Meringankan dan Memaksimalkan Kerja Guru.txt", "artikel kondisi pendidikan di indonesia.txt",
        "artikel pendidikan agama islam.txt","artikel pendidikan karakter.txt",
        "artikel pendidikan keberagaman.txt","artikel pendidikan motivasi hidup.txt", 
        "artikel pendidikan budi pekerti.txt","artikel pendidikan sosial.txt","artikel tips belajar selama pandemi.txt",
        "Kebijakan Pendidikan bagi Siswa SMA dan SMK di Jawa Timur Saat Pandemi COVID19.txt",
        "Penutupan Sekolah Akibat COVID-19 Berdampak pada 290 Juta Pelajar di Dunia.txt",
        "Sistem Pendidikan di Finlandia.txt","Sistem Pendidikan di Jepang.txt","Sistem Pendidikan di Korea.txt",
        "Sistem Pendidikan SD di Jepang.txt","Sistem Pendidikan SMA di Jepang.txt","Sistem Pendidikan SMP di Jepang.txt",
        "Sistem Pendidikan TK di Jepang.txt","Tips Mendampingi Anak belajar dari rumah.txt",
        "Transformasi Media Pembelajaran pada Masa Pandemi Covid-19.txt"]
artikel = []

#membuka 20 file artikel dan menjadikannya huruf kecil semua
for i in (judul):
   openfile = open(i,  encoding="utf8").read().lower()
   artikel.append(openfile)
print("Artikel yang dibuka : ",len(artikel),"\n")

artikel = "keputusan trump itu disebut sebuah kelompok kurdi sebagai tikaman ke punggung mengingat milisi kurdi adalah sekutu utama AS dalam mengalahkan ISIS di suriah. berbagai kalangan juga mengritik keputusan trump yang dinilai dapat membangkitkan kekuatan ISIS. AS restui aksi militer turki terhadap milisi kurdi di suriah trump dituduh berkhianat mengapa pengungsi suriah diminta segera meninggalkan istanbul kota terbesar di turki."

#membuat model n-gram agar dapat di implementasikan sesuai n-gram yang ingin dilakukan
def model_gram(artikel):
    token_sentence = nltk.sent_tokenize(str(artikel))

    # loop per kalimat, tambahkan tag <s> di awal kalimat dan </s> di akhir kalimat
    bag_of_sentences = []                           # array/list untuk menampung kata dari kalimat yang sudah ditokenisasi
    for sentence in token_sentence:
        tag_sentence = []
        token_word = nltk.word_tokenize(sentence)   #tokenisasi dari sentence ke word
        tag_sentence.append('<s>')                  #Menambahkan tag <s> di setiap awal kalimat
        for token in token_word:
            tag_sentence.append(token)
        tag_sentence.append('</s>')                 #Menambahkan tag </s> di setiap akhir kalimat
        bag_of_sentences.append(tag_sentence)       #Model n-gram siap digunakan
  
    return bag_of_sentences

#Membuat Model Unigram dari model n-gram yang telah dibuat sebelumnya.
model_ngram = model_gram(artikel)     

#Membuat unigram dari model_ngram 20 artikel
def model_unigram(model_ngram):
    unigram_freq = {}                       #Menghitung jumlah frekuensi kata unigram yang muncul dan memasukkan ke dict

    #for sentence in unigram:
    for sentence in model_ngram:
        for word in sentence:
            if word in unigram_freq:
                unigram_freq[word] += 1     #Mengupdate jumlah unigram, jika model unigram sudah ada dalam Dict
            else:
                unigram_freq[word] = 1      #Menambahkan jumlah unigram, jika model unigram belum ada dalam Dict
  
    return unigram_freq

#Membuat model bigram dari model n-gram yang telah dibuat sebelumnya dan menghitung frekuensinya
def model_bigram(model_ngram):
    bigram_freq = {}                                #Dict untuk menampung jumlah bigram yang muncul

    for sentence in model_ngram:
        for i in range(1, len(sentence)):
            bigram_model = (sentence[i-1],sentence[i])  #Membentuk model bigram dari 20 artikel
            if bigram_model in bigram_freq:
                bigram_freq[bigram_model] += 1          #Mengupdate jumlah bigram, jika model bigram sudah ada dalam Dict
            else:
                bigram_freq[bigram_model] = 1           #Menambahkan jumlah bigram, jika model bigram belum ada dalam Dict
  
    return bigram_freq

#Membuat model probability data bigram
def probability_bigram(model_ngram):
    bigram_freq = model_bigram(model_ngram)
    unigram_freq = model_unigram(model_ngram)
    prob_bigram = {}

    for sentence in model_ngram:
        for i in range(1,len(sentence)):
            curr_bigram = (sentence[i-1],sentence[i])
            
            if curr_bigram not in prob_bigram:
                prob_bigram[curr_bigram] = bigram_freq[curr_bigram]/unigram_freq[sentence[i-1]]   #Menghitung rumus Probability Bigram
    
    return prob_bigram

#Membuat fungsi Smoothing, dimana terdapat jumlah bigram yang bernilai 0
def smoothing(dicts):
    smooth = 0
    for cek in dicts:
        if dicts[cek] == 0:          #Mengecek Jumlah bigram yang bernilai 0
            for replace in dicts:
                dicts[replace] += 1  #Menambahkan 1 untuk setiap Jumlah Bigram yang ada dalam Dict      
                smooth = 1
      
    #Mencetak Hasil Success Smoothing atau Tidak perlu di Smoothing
    if smooth == 1:
        kata = "Berhasil di smoothing"
    else:
        kata = "Sudah tidak perlu di smoothing"
    
    return kata

#Membuat model probability Kalimat uji bigram, berdasarkan setiap kemunculan data uji bigram pada data latih
def probability_bigram_test(model_ngram,cek_bigram,cek_unigram):
    probability = {}
    for sentence in model_ngram:                  
        for i in range(1,len(sentence)):            
            curr_bigram = (sentence[i-1],sentence[i])

            if curr_bigram not in probability:
                probability[curr_bigram] = cek_bigram["Jumlah"][i-1]/cek_unigram['Jumlah'][i-1]

    return probability

#Menghitung Perplexity untuk mengevaluasi apakah model bagus atau tidak pada saat di uji
def Perplexity(bigram_kalimat_uji):
    perplexity = 0 
    for i in range(1,len(bigram_kalimat_uji["Probability"])):
        perplexity = math.pow((1/((bigram_kalimat_uji["Probability"][i-1])*(bigram_kalimat_uji["Probability"][i-1]))),1/len(bigram_kalimat_uji))

    return perplexity

#mengurutkan 10 data unigram terbanyak
unigram = model_unigram(model_ngram)
unigram_terbanyak = pd.DataFrame(list(unigram.items()),columns=["Kata","Jumlah"])
unigram_terbanyak.sort_values(['Jumlah'],ascending=False,inplace=True)
#print("10 Kata Unigram Terbanyak\n\n",unigram_terbanyak.head(10),"\n")

#Membuat Model Bigram
bigram_freq = model_bigram(model_ngram)   #Membangun data bigram
smooth = smoothing(bigram_freq)           #Melakukan smoothing, dengan mengecek jumlah frekuensi data bigram
#print("Data Latih",smooth,"\n")

#Membangun Dataframe Bigram agar lebih mudah dilihat jumlah serta probabilitynya.
prob_bigram = probability_bigram(model_ngram)

Bigram = pd.DataFrame(bigram_freq.items(),columns=["Bigram","Jumlah"])
prob = pd.DataFrame(prob_bigram.items(),columns=["Bigram","Probability"])
Probability_Bigram = prob['Probability']
Bigram['Probability'] = Probability_Bigram
print("Bigram Data Latih 20 Artikel\n\n",Bigram,"\n")

#Mengurutkan 10 probability bigram terbanyak
prob = pd.DataFrame(prob_bigram.items(),columns=["Bigram","Probability"])
Probability_Bigram = prob['Probability']
Bigram['Probability'] = Probability_Bigram

Bigram.sort_values(['Probability'],ascending=False, inplace=True)
print("10 Probability Bigram Tertinggi\n\n",Bigram.head(10),"\n")
print("\n########################################################\n\n")

"""**Testing Kalimat Uji :** 

Kalimat Uji 1 (Sesuai dengan topik data latih)
"""

#Kalimat uji 1 dengan topik yang sama, diambil dari potongan kalimat di salah satu artikel
kalimat_1 = "Pendidikan merupakan tiang pancang kebudayaan dan pondasi utama untuk membangun peradaban bangsa. Kesadaran akan arti penting pendidikan akan menentukan kualitas kesejahteraan lahir batin dan masa depan warganya. Oleh karena itu substansi pendidikan, materi pengajaran dan metodologi pembelajaran, serta manajemen pendidikan yang akuntabel susah seharusnya menjadi perhatian bagi para penyelenggara Negara."
lower_kalimat_1 = kalimat_1.lower()         #Membuat semua huruf kalimat uji 1 menjadi kecil
test_model1 = model_gram(lower_kalimat_1)   #Membuat model n-gram berdasarkan kalimat uji 1

#Model unigram kalimat uji
unigram_test = model_unigram(test_model1)

#cek frequensi unigram kalimat uji yang muncul berdasarkan data latih dari 20 artikel
cek_unigram = pd.DataFrame(unigram_test.items(), columns=["kata_uji","Jumlah"])

for i in range(len(cek_unigram)):
   filter = unigram_terbanyak[(unigram_terbanyak.Kata == cek_unigram["kata_uji"][i])]  #filter kata_uji dalam data latih
   if filter.size == 0:  #Jika sizenya 0 artinya kata_uji tidak ada pada data latih
       filter = filter.append({'Kata': cek_unigram["kata_uji"][i],'Jumlah':0 }, ignore_index=True)
       cek_unigram["Jumlah"].values[i] = filter["Jumlah"].values[0] #Mereplace jumlah kata uji sesuai kata uji dalam data latih
   else:                 #kata uji ada pada data latih
       cek_unigram["Jumlah"].values[i] = filter["Jumlah"].values[0] #Mereplace jumlah kata uji sesuai kata uji dalam data latih

print("Unigram Kalimat Uji 1 \n",cek_unigram,"\n")

#Membuat model bigram kalimat uji 1 dan menghitung frekuensinya
bigram_test = model_bigram(test_model1)

#Mengecek frekuensi bigram kalimat uji pada data latih
cek_bigram = pd.DataFrame(bigram_test.items(),columns=["Bigram_word_1","Jumlah"])

for i in range(len(cek_bigram)):
   filter = Bigram[(Bigram.Bigram == cek_bigram["Bigram_word_1"][i])]  #filter data bigram pada kalimat uji dalam data latih
   if filter.size == 0:  #Jika sizenya 0 artinya data bigram pada kalimat uji tidak ada pada data latih
       filter = filter.append({'Kata': cek_bigram["Bigram_word_1"][i],'Jumlah':0 }, ignore_index=True)
       cek_bigram["Jumlah"].values[i] = filter["Jumlah"].values[0]
   else:
       cek_bigram["Jumlah"].values[i] = filter["Jumlah"].values[0]

#Membuat Dataframe Kalimat Uji 1 agar mudah dilihat
prob = probability_bigram_test(test_model1,cek_bigram,cek_unigram)
prob_uji_1 = pd.DataFrame(prob.items(),columns=["Bigram_word_1","Probabilitas"])
cek_bigram["Probability"] = prob_uji_1["Probabilitas"]
print("Data Bigram Kalimat Uji 1\n\n",cek_bigram,"\n")

#Menghitung perplexity kalimat uji 1
perplexity_kalimat_1 = Perplexity(cek_bigram)
print("Perplexity kalimat uji 1 sebesar = ",perplexity_kalimat_1,"\n")
print("\n########################################################\n\n")

"""**Testing Kalimat Uji :** 

Kalimat Uji 2 (Berbeda dengan topik data latih)
"""
#Kalimat uji 1 dengan topik yang sama, diambil dari potongan kalimat di salah satu artikel
kalimat_2 = "COVID-19 adalah penyakit menular yang disebabkan oleh jenis virus corona yang baru ditemukan. Virus ini adalah virus baru dan penyakit yang tidak dikenal sebelum terjadinya wabah di Wuhan, Cina, pada bulan Desember 2019. Penularan dari orang ke orang diperkirakan terjadi melalui droplet ketika orang yang terinfeksi batuk atau bersin, mirip dengan bagaimana influenza dan patogen pernapasan lainnya yang dapat terhirup ke dalam paru-paru."
lower_kalimat_2 = kalimat_2.lower()         #Membuat semua huruf kalimat uji 1 menjadi kecil
test_model2 = model_gram(lower_kalimat_2)   #Membuat model n-gram berdasarkan kalimat uji 1

#Model unigram kalimat uji
unigram_test2 = model_unigram(test_model2)

#cek frequensi unigram kalimat uji yang muncul berdasarkan data latih dari 20 artikel
cek_unigram2 = pd.DataFrame(unigram_test2.items(), columns=["kata_uji","Jumlah"])

for i in range(len(cek_unigram2)):
   filter2 = unigram_terbanyak[(unigram_terbanyak.Kata == cek_unigram2["kata_uji"][i])]  #filter kata_uji dalam data latih
   if filter2.size == 0:  #Jika sizenya 0 artinya kata_uji tidak ada pada data latih
       filter2 = filter2.append({'Kata': cek_unigram2["kata_uji"][i],'Jumlah':0 }, ignore_index=True)
       cek_unigram2["Jumlah"].values[i] = filter2["Jumlah"].values[0] #Mereplace jumlah kata uji sesuai kata uji dalam data latih
   else:                  #kata uji ada pada data latih
       cek_unigram2["Jumlah"].values[i] = filter2["Jumlah"].values[0] #Mereplace jumlah kata uji sesuai kata uji dalam data latih

print("Unigram Kalimat Uji 2 \n",cek_unigram2,"\n")

#Membuat model bigram kalimat uji 2 dan menghitung frekuensinya
bigram_test2 = model_bigram(test_model2)

#Mengecek frekuensi bigram kalimat uji pada data latih
cek_bigram2 = pd.DataFrame(bigram_test2.items(),columns=["Bigram_word_2","Jumlah"])

for i in range(len(cek_bigram2)):
   filter2 = Bigram[(Bigram.Bigram == cek_bigram2["Bigram_word_2"][i])]  #filter data bigram pada kalimat uji dalam data latih
   if filter2.size == 0:  #Jika sizenya 0 artinya data bigram pada kalimat uji tidak ada pada data latih
       filter2 = filter2.append({'Kata': cek_bigram2["Bigram_word_2"][i],'Jumlah':0 }, ignore_index=True)
       cek_bigram2["Jumlah"].values[i] = filter2["Jumlah"].values[0]
   else:
       cek_bigram2["Jumlah"].values[i] = filter2["Jumlah"].values[0]

#Membuat Dataframe Kalimat Uji 2 agar mudah dilihat
prob2 = probability_bigram_test(test_model2,cek_bigram2,cek_unigram2)
prob_uji_2 = pd.DataFrame(prob2.items(),columns=["Bigram_word_2","Probabilitas"])
cek_bigram2["Probability"] = prob_uji_2["Probabilitas"]
print("Data Bigram Kalimat Uji 2\n\n",cek_bigram2,"\n")

#Menghitung perplexity kalimat uji 2
perplexity_kalimat_2 = Perplexity(cek_bigram2)
print("Perplexity kalimat uji 2 sebesar = ",perplexity_kalimat_2,"\n")
print("\n########################## BONUS ##############################\n\n")

"""**Model Trigram**"""
def model_trigram(model_ngram):
    trigram_freq = {}

    for sentence in model_ngram:
        for i in range(2, len(sentence)):
          trigram_model = (sentence[i-2],sentence[i-1],sentence[i])  #Membentuk model trigram dari 20 artikel
          if trigram_model in trigram_freq:
            trigram_freq[trigram_model] += 1            #Mengupdate jumlah trigram, jika model trigram sudah ada dalam Dict
          else:
            trigram_freq[trigram_model] = 1             #Menambahkan jumlah trigram, jika model trigram belum ada dalam Dict
    
    return trigram_freq

#Membuat model probability data trigram
def probability_trigram(model_ngram):
    bigram_freq = model_bigram(model_ngram)
    trigram_freq = model_trigram(model_ngram)
    prob_trigram = {}

    for sentence in model_ngram:
        for i in range(2,len(sentence)):
            curr_bigram = (sentence[i-2],sentence[i-1])
            curr_trigram = (sentence[i-2],sentence[i-1],sentence[i])
            
            if curr_trigram not in prob_trigram:
                prob_trigram[curr_trigram] = trigram_freq[curr_trigram]/bigram_freq[curr_bigram]   #Menghitung rumus Probability Bigram
  
    return prob_trigram


#Membangun Dataframe Trigram agar lebih mudah dilihat jumlah serta probabilitynya.
trigram_freq = model_trigram(model_ngram)
prob_trigram = probability_trigram(model_ngram)

Trigram = pd.DataFrame(trigram_freq.items(),columns=["Tigram","Jumlah"])
probtri = pd.DataFrame(prob_trigram.items(),columns=["Tigram","Probability"])
Probability_Trigram = probtri['Probability']
Trigram['Probability'] = Probability_Trigram
print("Model Trigram \n\n",Trigram.tail(2))

#Membandingkan Perplexity Model Bigram dan Trigram
Perplexity_Bigram = Perplexity(Bigram)
Perplexity_Trigram = Perplexity(Trigram)
print("Perplexity Model Bigram  : ",Perplexity_Bigram)
print("Perplexity Model Trigram : ",Perplexity_Trigram)

Unigram = pd.DataFrame(unigram.items(),columns=["Unigram","Jumlah"])
print(Unigram)